<!doctype html>
<html lang="ko-KR" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-infra/trainium" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.0">
<title data-rh="true">trainium | AI on EKS</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://awslabs.github.io/ai-on-eks/ko/docs/infra/trainium"><meta data-rh="true" property="og:locale" content="ko_KR"><meta data-rh="true" property="og:locale:alternate" content="en_US"><meta data-rh="true" name="docusaurus_locale" content="ko"><meta data-rh="true" name="docsearch:language" content="ko"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="trainium | AI on EKS"><meta data-rh="true" name="description" content="EKS에서 ML 모델을 배포하려면 GPU 또는 Neuron 인스턴스에 대한 액세스가 필요합니다. 배포가 작동하지 않는 경우 이러한 리소스에 대한 액세스가 누락되어 있는 경우가 많습니다. 또한 일부 배포 패턴은 Karpenter 자동 확장 및 정적 노드 그룹에 의존합니다. 노드가 초기화되지 않는 경우 Karpenter 또는 노드 그룹의 로그를 확인하여 문제를 해결하세요."><meta data-rh="true" property="og:description" content="EKS에서 ML 모델을 배포하려면 GPU 또는 Neuron 인스턴스에 대한 액세스가 필요합니다. 배포가 작동하지 않는 경우 이러한 리소스에 대한 액세스가 누락되어 있는 경우가 많습니다. 또한 일부 배포 패턴은 Karpenter 자동 확장 및 정적 노드 그룹에 의존합니다. 노드가 초기화되지 않는 경우 Karpenter 또는 노드 그룹의 로그를 확인하여 문제를 해결하세요."><link data-rh="true" rel="icon" href="/ai-on-eks/ko/img/header-icon.png"><link data-rh="true" rel="canonical" href="https://awslabs.github.io/ai-on-eks/ko/docs/infra/trainium"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/ai-on-eks/docs/infra/trainium" hreflang="en-US"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/ai-on-eks/ko/docs/infra/trainium" hreflang="ko-KR"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/ai-on-eks/docs/infra/trainium" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"EKS 기반 Trainium","item":"https://awslabs.github.io/ai-on-eks/ko/docs/infra/trainium"}]}</script><link rel="stylesheet" href="/ai-on-eks/ko/assets/css/styles.c270b852.css">
<script src="/ai-on-eks/ko/assets/js/runtime~main.ef4834e8.js" defer="defer"></script>
<script src="/ai-on-eks/ko/assets/js/main.1f45c938.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus"><div role="region" aria-label="본문으로 건너뛰기"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">본문으로 건너뛰기</a></div><div class="theme-announcement-bar announcementBar_mb4j" style="background-color:#667eea;color:#ffffff" role="banner"><div class="announcementBarPlaceholder_vyr4"></div><div class="content_knG7 announcementBarContent_xLdY">GenAI on EKS workshop series! <a target="_blank" rel="noopener noreferrer" href="https://aws-experience.com/emea/smb/events/series/get-hands-on-with-amazon-eks?trk=9be4af2e-2339-40ae-b5e9-57b6a7704c36&sc_channel=el" style="color: #ffffff; text-decoration: underline; font-weight: bold; margin-left: 10px;">Register now →</a></div><button type="button" aria-label="닫기" class="clean-btn close closeButton_CVFx announcementBarClose_gvF7"><svg viewBox="0 0 15 15" width="14" height="14"><g stroke="currentColor" stroke-width="3.1"><path d="M.75.75l13.5 13.5M14.25.75L.75 14.25"></path></g></svg></button></div><nav aria-label="메인" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="사이드바 펼치거나 접기" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ai-on-eks/ko/"><div class="navbar__logo"><img src="/ai-on-eks/ko/img/header-icon.png" alt="AIoEKS 로고" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/ai-on-eks/ko/img/header-icon.png" alt="AIoEKS 로고" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/ai-on-eks/ko/docs/infra">인프라</a><a class="navbar__item navbar__link" href="/ai-on-eks/ko/docs/blueprints">블루프린트</a><a class="navbar__item navbar__link" href="/ai-on-eks/ko/docs/guidance">가이드</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/awslabs/ai-on-eks" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>한국어</a><ul class="dropdown__menu"><li><a href="/ai-on-eks/docs/infra/trainium" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en-US">English</a></li><li><a href="/ai-on-eks/ko/docs/infra/trainium" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="ko-KR">한국어</a></li></ul></div><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="어두운 모드와 밝은 모드 전환하기 (현재 system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input id="search_input_react" type="search" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="맨 위로 스크롤하기" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="문서 사이드바" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-on-eks/ko/docs/infra"><span title="소개" class="linkLabel_WmDU"> 소개</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-on-eks/ko/docs/infra/jark"><span title="EKS 기반 JARK" class="linkLabel_WmDU">EKS 기반 JARK</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-on-eks/ko/docs/infra/aibrix"><span title="EKS 기반 AIBrix" class="linkLabel_WmDU">EKS 기반 AIBrix</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-on-eks/ko/docs/infra/emr-spark-rapids"><span title="EMR NVIDIA Spark-RAPIDS" class="linkLabel_WmDU">EMR NVIDIA Spark-RAPIDS</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-on-eks/ko/docs/infra/inference-ready-cluster"><span title="추론 준비 클러스터" class="linkLabel_WmDU">추론 준비 클러스터</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-on-eks/ko/docs/infra/jupyterhub"><span title="EKS 기반 JupyterHub" class="linkLabel_WmDU">EKS 기반 JupyterHub</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" href="/ai-on-eks/ko/docs/infra/trainium"><span title="EKS 기반 Trainium" class="linkLabel_WmDU">EKS 기반 Trainium</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-on-eks/ko/docs/infra/troubleshooting"><span title="문제 해결" class="linkLabel_WmDU">문제 해결</span></a></li></ul></nav><button type="button" title="사이드바 숨기기" aria-label="사이드바 숨기기" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="탐색 경로"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="홈" class="breadcrumbs__link" href="/ai-on-eks/ko/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">EKS 기반 Trainium</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">이 페이지에서</button></div><div class="theme-doc-markdown markdown"><div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>경고</div><div class="admonitionContent_BuS1"><p>EKS에서 ML 모델을 배포하려면 GPU 또는 Neuron 인스턴스에 대한 액세스가 필요합니다. 배포가 작동하지 않는 경우 이러한 리소스에 대한 액세스가 누락되어 있는 경우가 많습니다. 또한 일부 배포 패턴은 Karpenter 자동 확장 및 정적 노드 그룹에 의존합니다. 노드가 초기화되지 않는 경우 Karpenter 또는 노드 그룹의 로그를 확인하여 문제를 해결하세요.</p></div></div>
<header><h1>EKS 기반 AWS Trainium</h1></header>
<p><a href="https://aws.amazon.com/machine-learning/trainium/" target="_blank" rel="noopener noreferrer">AWS Trainium</a>은 고성능 딥러닝(DL) 훈련을 혁신하는 고급 ML 가속기입니다. AWS Trainium 칩으로 구동되는 <code>Trn1</code> 인스턴스는 <strong>1000억개 이상의 파라미터</strong> 모델의 고성능 DL 훈련을 위해 특별히 제작되었습니다. 탁월한 성능을 위해 세심하게 설계된 Trn1 인스턴스는 AWS에서 인기 있는 자연어 처리(NLP) 모델 훈련에 특화되어 GPU 기반 EC2 인스턴스에 비해 <strong>최대 50% 비용 절감</strong>을 제공합니다. 이러한 비용 효율성으로 인해 성능 저하 없이 최적화된 훈련 비용을 원하는 데이터 과학자와 ML 실무자에게 매력적인 옵션이 됩니다.</p>
<p>Trn1 인스턴스 기능의 핵심에는 <a href="https://awsdocs-neuron.readthedocs-hosted.com/en/latest/" target="_blank" rel="noopener noreferrer">AWS Neuron SDK</a>가 있습니다. 이 소프트웨어 개발 키트는 <a href="https://pytorch.org/" target="_blank" rel="noopener noreferrer">PyTorch</a>, <a href="https://tensorflow.org/" target="_blank" rel="noopener noreferrer">TensorFlow</a>, <a href="https://huggingface.co/docs/accelerate/usage_guides/megatron_lm" target="_blank" rel="noopener noreferrer">Megatron-LM</a>, <a href="https://huggingface.co/" target="_blank" rel="noopener noreferrer">Hugging Face</a>와 같은 주요 ML 프레임워크 및 라이브러리와 원활하게 통합됩니다. Neuron SDK를 통해 개발자는 몇 줄의 코드 변경만으로 Trainium에서 NLP, 컴퓨터 비전 및 추천 모델을 쉽게 훈련할 수 있습니다.</p>
<p>이 블루프린트에서는 Trainium 노드 그룹(<code>Trn1.32xlarge</code> 및 <code>Trn1n.32xlarge</code>)과 필요한 모든 플러그인(EC2용 EFA 패키지, Neuron Device K8s 플러그인 및 EFA K8s 플러그인)이 포함된 <a href="https://docs.aws.amazon.com/eks/latest/userguide/clusters.html" target="_blank" rel="noopener noreferrer">Amazon EKS 클러스터</a>를 안전하게 배포하는 방법을 배웁니다. 배포가 완료되면 WikiCorpus 데이터셋을 사용하여 분산 PyTorch 사전 훈련으로 BERT-large(Bidirectional Encoder Representations from Transformers) 모델을 훈련하는 방법을 배웁니다. 분산 훈련 작업을 예약하기 위해 <a href="https://volcano.sh/en/" target="_blank" rel="noopener noreferrer">Volcano Scheduler</a>와 함께 <a href="https://pytorch.org/torchx/latest/" target="_blank" rel="noopener noreferrer">TorchX</a>를 활용합니다. 또한 <code>neuron-top</code>을 사용하여 훈련 중 뉴런 활동을 모니터링할 수 있습니다.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="trainium-장치-아키텍처">Trainium 장치 아키텍처<a href="#trainium-장치-아키텍처" class="hash-link" aria-label="Trainium 장치 아키텍처에 대한 직접 링크" title="Trainium 장치 아키텍처에 대한 직접 링크" translate="no">​</a></h4>
<p>각 Trainium 장치(칩)는 두 개의 뉴런 코어로 구성됩니다. <code>Trn1.32xlarge</code> 인스턴스의 경우 <code>16개의 Trainium 장치</code>가 결합되어 총 <code>32개의 Neuron 코어</code>가 됩니다. 아래 다이어그램은 Neuron 장치 아키텍처의 시각적 표현을 제공합니다:</p>
<p><img decoding="async" loading="lazy" alt="Trainium Device" src="/ai-on-eks/ko/assets/images/neuron-device-b6418f956d103a5da9e7087ba07cf949.png" width="625" height="556" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="aws-neuron-드라이버">AWS Neuron 드라이버<a href="#aws-neuron-드라이버" class="hash-link" aria-label="AWS Neuron 드라이버에 대한 직접 링크" title="AWS Neuron 드라이버에 대한 직접 링크" translate="no">​</a></h4>
<p>Neuron 드라이버는 Trainium/Inferentia 인스턴스와 같은 AWS Inferentia 기반 가속기의 호스트 운영 체제에 설치되는 필수 소프트웨어 구성 요소 세트입니다. 주요 기능은 가속기 하드웨어와 기본 운영 체제 간의 상호 작용을 최적화하여 원활한 통신과 가속기의 컴퓨팅 기능의 효율적인 활용을 보장하는 것입니다.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="aws-neuron-런타임">AWS Neuron 런타임<a href="#aws-neuron-런타임" class="hash-link" aria-label="AWS Neuron 런타임에 대한 직접 링크" title="AWS Neuron 런타임에 대한 직접 링크" translate="no">​</a></h4>
<p>Neuron 런타임은 Inferentia 및 Trainium Neuron 장치에 액세스하기 위한 API를 제공하는 커널 드라이버와 C/C++ 라이브러리로 구성됩니다. TensorFlow, PyTorch 및 Apache MXNet용 Neuron ML 프레임워크 플러그인은 Neuron 런타임을 사용하여 NeuronCore에서 모델을 로드하고 실행합니다.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="kubernetes용-aws-neuron-device-plugin">Kubernetes용 AWS Neuron Device Plugin<a href="#kubernetes용-aws-neuron-device-plugin" class="hash-link" aria-label="Kubernetes용 AWS Neuron Device Plugin에 대한 직접 링크" title="Kubernetes용 AWS Neuron Device Plugin에 대한 직접 링크" translate="no">​</a></h4>
<p>Kubernetes용 AWS Neuron Device Plugin은 EKS 클러스터 내에서 Trainium/Inferentia 장치를 시스템 하드웨어 리소스로 승격시키는 구성 요소입니다. <a href="https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/" target="_blank" rel="noopener noreferrer">DaemonSet</a>으로 배포되어 장치 플러그인이 노드 및 파드 주석을 업데이트할 수 있는 적절한 권한을 보장하여 Inferentia 장치를 Kubernetes 파드와 원활하게 통합합니다.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="fsx-for-lustre">FSx for Lustre<a href="#fsx-for-lustre" class="hash-link" aria-label="FSx for Lustre에 대한 직접 링크" title="FSx for Lustre에 대한 직접 링크" translate="no">​</a></h4>
<p>이 블루프린트에서는 TorchX를 사용하여 2개의 trn1.32xlarge(또는 trn1n.32xlarge) 인스턴스에 분산된 64개의 워커(인스턴스당 32개 워커)를 사용하는 DataParallel BERT phase1 사전 훈련 작업을 시작합니다. BERT phase1 사전 훈련 프로세스는 훈련 데이터로 50GB 이상의 상당한 WikiCorpus 데이터셋을 사용합니다. 대용량 데이터셋을 효율적으로 처리하기 위해 훈련 컨테이너 이미지 내에 데이터셋을 포함하거나 각 작업 시작 시 다운로드하는 것은 실용적이지 않습니다. 대신 여러 컴퓨팅 인스턴스가 훈련 데이터셋을 동시에 처리할 수 있도록 공유 파일 시스템 스토리지를 활용합니다.</p>
<p>이 목적을 위해 FSx for Lustre는 머신 러닝 워크로드에 이상적인 솔루션으로 부상합니다. 초당 수백 기가바이트의 처리량, 수백만 IOPS 및 밀리초 미만의 지연 시간으로 대규모 데이터 세트를 처리할 수 있는 공유 파일 시스템 스토리지를 제공합니다. FSx CSI 컨트롤러를 통해 Persistent Volume Claims(PVC)를 사용하여 FSx for Lustre를 동적으로 생성하고 파일 시스템을 파드에 연결하여 분산 훈련 프로세스와 공유 파일 스토리지의 원활한 통합을 가능하게 합니다.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="torchx">TorchX<a href="#torchx" class="hash-link" aria-label="TorchX에 대한 직접 링크" title="TorchX에 대한 직접 링크" translate="no">​</a></h4>
<p><a href="https://pytorch.org/torchx/main/quickstart.html" target="_blank" rel="noopener noreferrer">TorchX</a> SDK 또는 CLI는 PyTorch 작업을 Kubernetes에 손쉽게 제출하는 기능을 제공합니다. Slurm, Ray, AWS Batch, Kubeflow Pipelines 및 Airflow와 같은 인기 있는 작업 스케줄러를 활용하면서 하이퍼파라미터 최적화, 모델 서빙 및 분산 데이터 병렬과 같은 사전 정의된 구성 요소를 정교한 파이프라인에 연결하는 기능을 제공합니다.</p>
<p>TorchX Kubernetes 스케줄러는 Kubernetes 클러스터에 설치해야 하는 <a href="https://volcano.sh/en/docs/" target="_blank" rel="noopener noreferrer">Volcano Scheduler</a>에 의존합니다. 다중 복제본/다중 역할 실행에는 갱 스케줄링이 필수적이며, 현재 Kubernetes 내에서 이 요구 사항을 충족하는 유일하게 지원되는 스케줄러는 Volcano입니다.</p>
<p>TorchX는 Airflow 및 Kubeflow Pipelines와 원활하게 통합될 수 있습니다. 이 블루프린트에서는 로컬 머신/Cloud9 IDE에 TorchX CLI를 설치하고 이를 사용하여 EKS 클러스터에 작업 제출을 트리거합니다. 그러면 EKS 클러스터에서 실행 중인 Volcano 스케줄러 큐에 작업이 제출됩니다.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="volcano-scheduler">Volcano Scheduler<a href="#volcano-scheduler" class="hash-link" aria-label="Volcano Scheduler에 대한 직접 링크" title="Volcano Scheduler에 대한 직접 링크" translate="no">​</a></h4>
<p><a href="https://volcano.sh/en/docs/" target="_blank" rel="noopener noreferrer">Volcano Scheduler</a>는 다양한 워크로드를 효율적으로 관리하도록 설계된 커스텀 Kubernetes 배치 스케줄러로, 머신 러닝과 같은 리소스 집약적인 작업에 특히 적합합니다. Volcano Queue는 PodGroup의 컬렉션으로 작동하며 FIFO(선입선출) 방식을   채택하여 리소스 할당의 기반을 형성합니다. <code>vcjob</code>이라고도 알려진 VolcanoJob은 Volcano를 위해 특별히 설계된 Custom Resource Definition(CRD) 객체입니다. 지정된 스케줄러, 최소 멤버 요구 사항, 작업 정의, 수명 주기 관리, 특정 큐 할당 및 우선 순위 설정을 포함한 고급 기능을 제공하여 일반 Kubernetes 작업과 차별화됩니다. VolcanoJob은 머신 러닝, 빅 데이터 애플리케이션 및 과학 컴퓨팅과 같은 고성능 컴퓨팅 시나리오에 이상적으로 적합합니다.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="솔루션-아키텍처">솔루션 아키텍처<a href="#솔루션-아키텍처" class="hash-link" aria-label="솔루션 아키텍처에 대한 직접 링크" title="솔루션 아키텍처에 대한 직접 링크" translate="no">​</a></h3>
<p><img decoding="async" loading="lazy" alt="Alt text" src="/ai-on-eks/ko/assets/images/trainium-on-eks-arch-7d551d7182d87be5c787267ec74ff22d.png" width="12492" height="7950" class="img_ev3q"></p>
<div class="collapsibleContent_q3kw"><div class="header_QCEw"><h2><span>솔루션 배포</span></h2><span class="icon_PckA">👈</span></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="aws-cloudwatch-및-neuron-monitor를-사용한-관측성">AWS CloudWatch 및 Neuron Monitor를 사용한 관측성<a href="#aws-cloudwatch-및-neuron-monitor를-사용한-관측성" class="hash-link" aria-label="AWS CloudWatch 및 Neuron Monitor를 사용한 관측성에 대한 직접 링크" title="AWS CloudWatch 및 Neuron Monitor를 사용한 관측성에 대한 직접 링크" translate="no">​</a></h3>
<p>이 블루프린트는 컨테이너화된 워크로드에 대한 포괄적인 모니터링을 제공하는 관리형 애드온으로 CloudWatch Observability Agent를 배포합니다. CPU 및 메모리 사용률과 같은 주요 성능 메트릭을 추적하기 위한 컨테이너 인사이트를 포함합니다. 또한 블루프린트는 고성능 GPU 워크로드 모니터링에 필수적인 NVIDIA의 DCGM 플러그인을 사용하여 GPU 메트릭을 통합합니다. AWS Inferentia 또는 Trainium에서 실행되는 머신 러닝 모델의 경우 <a href="https://awsdocs-neuron.readthedocs-hosted.com/en/latest/tools/neuron-sys-tools/neuron-monitor-user-guide.html#neuron-monitor-user-guide" target="_blank" rel="noopener noreferrer">Neuron Monitor 플러그인</a>이 Neuron 관련 메트릭을 캡처하고 보고하기 위해 추가됩니다.</p>
<p>컨테이너 인사이트, GPU 성능 및 Neuron 메트릭을 포함한 모든 메트릭은 Amazon CloudWatch로 전송되어 실시간으로 모니터링하고 분석할 수 있습니다. 배포가 완료되면 CloudWatch 콘솔에서 직접 이러한 메트릭에 액세스하여 워크로드를 효과적으로 관리하고 최적화할 수 있습니다.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="torchx-및-eks를-사용한-trainium에서의-분산-pytorch-훈련">TorchX 및 EKS를 사용한 Trainium에서의 분산 PyTorch 훈련<a href="#torchx-및-eks를-사용한-trainium에서의-분산-pytorch-훈련" class="hash-link" aria-label="TorchX 및 EKS를 사용한 Trainium에서의 분산 PyTorch 훈련에 대한 직접 링크" title="TorchX 및 EKS를 사용한 Trainium에서의 분산 PyTorch 훈련에 대한 직접 링크" translate="no">​</a></h3>
<p>이 예제에서는 WikiCorpus 데이터셋을 사용하여 BERT-large 모델에서 DataParallel 기반 phase1 사전 훈련을 수행합니다. 작업을 실행하기 위해 TorchX를 사용하여 인스턴스당 32개의 워커가 있는 두 개의 <code>trn1.32xlarge</code> 인스턴스에서 작업을 시작합니다. <code>trn1n.32xlarge</code> 노드 그룹에서도 동일한 작업을 실행할 수 있습니다.</p>
<p>작업 실행을 최대한 자동화하기 위해 세 개의 셸 스크립트를 만들었습니다.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="1단계-bert-large-모델-사전-훈련을-위한-pytorch-neuron-컨  테이너용-docker-이미지-생성">1단계: BERT-large 모델 사전 훈련을 위한 PyTorch Neuron 컨테이너용 Docker 이미지 생성<a href="#1단계-bert-large-모델-사전-훈련을-위한-pytorch-neuron-컨테이너용-docker-이미지-생성" class="hash-link" aria-label="1단계: BERT-large 모델 사전 훈련을 위한 PyTorch Neuron 컨테이너용 Docker 이미지 생성에 대한 직접 링크" title="1단계: BERT-large 모델 사전 훈련을 위한 PyTorch Neuron 컨테이너용 Docker 이미지 생성에 대한 직접 링크" translate="no">​</a></h4>
<p>이 단계에서는 새 Docker 이미지를 만들고 이 이미지를 ECR 리포지토리에 푸시합니다. Dockerfile은 AWS Neuron 리포지토리, Python 종속성 및 PyTorch와 BERT 사전 훈련에 필요한 기타 필수 도구와 같은 필요한 소프트웨어 패키지의 설치를 처리합니다. 원활한 실행과 최적의 성능을 보장하기 위해 다양한 환경 변수를 구성합니다. 이미지에는 BERT 사전 훈련 프로세스에 중요한 GitHub에서 가져온 BERT 사전 훈련 스크립트와 requirements.txt 파일과 같은 중요한 구성 요소가 포함되어 있습니다. 또한 검증 목적의 기본 환경 테스트 스크립트도 포함됩니다. 이 Docker 이미지는 AWS Neuron 최적화를 통합하면서 PyTorch를 사용한 효율적인 BERT 사전 훈련을 위한 포괄적인 환경을 제공합니다.</p>
<div class="theme-admonition theme-admonition-caution admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>주의</div><div class="admonitionContent_BuS1"><p>이 단계에서는 7GB 이상 크기의 AMD64(x86-64) Docker 이미지를 생성합니다. 따라서 이 프로세스를 위해 충분한 스토리지 용량을 갖춘 Docker 클라이언트가 설치된 AWS Cloud9/EC2 AMD64(x86-64) 인스턴스를 활용하는 것이 좋습니다.</p></div></div>
<div class="theme-admonition theme-admonition-caution admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>주의</div><div class="admonitionContent_BuS1"><p>EKS 클러스터가 배포된 것과 다른 Cloud9 IDE/EC2 인스턴스에서 이 스크립트를 실행하는 경우 동일한 IAM 역할이 Cloud9 IDE/EC2 인스턴스에 사용되거나 연결되어 있는지 확인하는 것이 필수적입니다. Cloud9 IDE/EC2에 별도의 IAM 역할을 선호하는 경우 EKS 클러스터의 aws-auth 구성 맵에 추가하여 역할이 EKS 클러스터 인증 권한을 부여받아야 합니다. 이러한 예방 조치를 취하면 인스턴스와 EKS 클러스터 간의 원활한 통신이 가능하여 스크립트가 의도한 대로 작동합니다.</p></div></div>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token builtin class-name">cd</span><span class="token plain"> infra/trainium-inferentia/examples/dp-bert-large-pretrain</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token function" style="color:#d73a49">chmod</span><span class="token plain"> +x </span><span class="token number" style="color:#36acaa">1</span><span class="token plain">-bert-pretrain-build-image.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./1-bert-pretrain-build-image.sh</span><br></span></code></pre></div></div>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Admin:~/environment/data-on-eks/infra/trainium-inferentia/examples/dp-bert-large-pretrain (trainium-part2) $ ./1-bert-pretrain-build-image.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Did you install docker on AMD64(x86-64) machine (y/n): y</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Enter the ECR region: us-west-2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ECR repository &#x27;eks_torchx_test&#x27; already exists.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Repository URL: &lt;YOUR_ACCOUNT_ID&gt;.dkr.ecr.us-west-2.amazonaws.com/eks_torchx_test</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Building and Tagging Docker image... &lt;YOUR_ACCOUNT_ID&gt;.dkr.ecr.us-west-2.amazonaws.com/eks_torchx_test:bert_pretrain</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[+] Building 2.4s (26/26) FINISHED</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> =&gt; [internal] load build definition from Dockerfile.bert_pretrain                                                                                                                   0.0s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> =&gt; =&gt; transferring dockerfile: 5.15kB                                                                                                                                               0.0s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> =&gt; [internal] load .dockerignore                                                                                                                                                    0.0s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> =&gt; =&gt; transferring context: 2B                                                                                                                                                      0.0s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> =&gt; [internal] load metadata for docker.io/library/ubuntu:20.04                                                                                                                      0.7s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> =&gt; [ 1/22] FROM docker.io/library/ubuntu:20.04@sha256:c9820a44b950956a790c354700c1166a7ec648bc0d215fa438d3a339812f1d01                                                              0.0s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">bert_pretrain: digest: sha256:1bacd5233d1a87ca1d88273c5a7cb131073c6f390f03198a91dc563158485941 size: 4729</span><br></span></code></pre></div></div>
<p>AWS 콘솔에 로그인하여 ECR의 ECR 리포지토리(<code>&lt;YOUR_ACCOUNT_ID&gt;.dkr.ecr.&lt;REGION&gt;.amazonaws.com/eks_torchx_test</code>)와 이미지 태그(<code>bert_pretrain</code>)를 확인합니다.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="2단계-bert-모델용-wikicorpus-사전-훈련-데이터셋을-fsx-for-lustre-파일-시스템에-복사">2단계: BERT 모델용 WikiCorpus 사전 훈련 데이터셋을 FSx for Lustre 파일 시스템에 복사<a href="#2단계-bert-모델용-wikicorpus-사전-훈련-데이터셋을-fsx-for-lustre-파일-시스템에-복사" class="hash-link" aria-label="2단계: BERT 모델용 WikiCorpus 사전 훈련 데이터셋을 FSx for Lustre 파일 시스템에 복사에 대한 직접 링크" title="2단계: BERT 모델용 WikiCorpus 사전 훈련 데이터셋을 FSx for Lustre 파일 시스템에 복사에 대한 직접 링크" translate="no">​</a></h4>
<p>이 단계에서는 분산 모드에서 여러 Trainium 인스턴스가 BERT 모델을 훈련하는 데 중요한 WikiCorpus 사전 훈련 데이터셋을 FSx for Lustre 파일 시스템으로 쉽게 전송합니다. 이를 위해 파일 시스템에 대한 액세스를 제공하는 AWS CLI 컨테이너가 포함된 <code>cmd-shell</code> 파드에 로그인합니다.</p>
<p>컨테이너 내부에 들어가면 S3 버킷(<code>s3://neuron-s3/training_datasets/bert_pretrain_wikicorpus_tokenized_hdf5/bert_pretrain_wikicorpus_tokenized_hdf5_seqlen128.tar</code>)에서 WikiCorpus 데이터셋을 복사합니다. 그런 다음 데이터셋이 압축 해제되어 후속 BERT 모델 사전 훈련 프로세스에서 사용할 준비가 된 콘텐츠에 액세스할 수 있습니다.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl </span><span class="token builtin class-name">exec</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-i</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-t</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> default cmd-shell </span><span class="token parameter variable" style="color:#36acaa">-c</span><span class="token plain"> app -- </span><span class="token function" style="color:#d73a49">sh</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-c</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;clear; (bash || ash || sh)&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 컨테이너에 로그인한 후</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">yum </span><span class="token function" style="color:#d73a49">install</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">tar</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token builtin class-name">cd</span><span class="token plain"> /data</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">aws s3 </span><span class="token function" style="color:#d73a49">cp</span><span class="token plain"> s3://neuron-s3/training_datasets/bert_pretrain_wikicorpus_tokenized_hdf5/bert_pretrain_wikicorpus_tokenized_hdf5_seqlen128.tar </span><span class="token builtin class-name">.</span><span class="token plain"> --no-sign-request</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token function" style="color:#d73a49">chmod</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">744</span><span class="token plain"> bert_pretrain_wikicorpus_tokenized_hdf5_seqlen128.tar</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token function" style="color:#d73a49">tar</span><span class="token plain"> xvf bert_pretrain_wikicorpus_tokenized_hdf5_seqlen128.tar</span><br></span></code></pre></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="3단계-neuron_parallel_compile을-사용하여-bert-그래프-사전-컴파일">3단계: neuron_parallel_compile을 사용하여 BERT 그래프 사전 컴파일<a href="#3단계-neuron_parallel_compile을-사용하여-bert-그래프-사전-컴파일" class="hash-link" aria-label="3단계: neuron_parallel_compile을 사용하여 BERT 그래프 사전 컴파일에 대한 직접 링크" title="3단계: neuron_parallel_compile을 사용하여 BERT 그래프 사전 컴파일에 대한 직접 링크" translate="no">​</a></h4>
<p>PyTorch Neuron은 모델 그래프를 추출하고 병렬로 컴파일하여 그래프 컴파일 시간을 크게 줄이는 <a href="https://awsdocs-neuron.readthedocs-hosted.com/en/latest/frameworks/torch/torch-neuronx/api-reference-guide/training/pytorch-neuron-parallel-compile.html" target="_blank" rel="noopener noreferrer">neuron_parallel_compile</a>이라는 귀중한 도구를 도입합니다. 이 최적화 기술은 프로세스를 가속화하고 더 빠른 모델 컴파일을 가져옵니다. 컴파일된 그래프는 모델 훈련 중 워커 노드가 액세스할 수 있는 FSx for Lustre 공유 스토리지 볼륨에 저장됩니다. 이 효율적인 접근 방식은 훈련 프로세스를 간소화하고 전반적인 성능을 향상시켜 PyTorch Neuron의 기능을 최대한 활용합니다.</p>
<p>다음 명령을 실행합니다. 이 스크립트는 사용자에게 kubeconfig를 구성하라는 메시지를 표시하고 <code>trn1_dist_ddp.py</code>가 있는 <code>lib</code> 폴더의 존재를 확인합니다. Docker 자격 증명을 설정하고 Kubernetes용 <strong>TorchX</strong> 클라이언트를 설치합니다. TorchX를 사용하여 스크립트는 최적화된 성능으로 BERT 그래프를 컴파일하는 Kubernetes 작업을 실행합니다. 또한 TorchX는 다른 Docker 이미지를 만들고 동일한 리포지토리 내의 ECR 리포지토리에 푸시합니다. 이 이미지는 후속 사전 컴파일 파드에서 활용되어 전체 BERT 모델 훈련 프로세스를 최적화합니다.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token builtin class-name">cd</span><span class="token plain"> infra/trainium-inferentia/examples/dp-bert-large-pretrain</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token function" style="color:#d73a49">chmod</span><span class="token plain"> +x </span><span class="token number" style="color:#36acaa">2</span><span class="token plain">-bert-pretrain-precompile.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./2-bert-pretrain-precompile.sh</span><br></span></code></pre></div></div>
<p><code>kubectl get pods</code> 또는 <code>kubectl get vcjob</code>을 실행하여 파드 상태를 확인할 수 있습니다. 성공적인 출력은 아래와 같습니다.</p>
<p><img decoding="async" loading="lazy" alt="Alt text" src="/ai-on-eks/ko/assets/images/pre-compile-pod-status-a957a723dd43219aacf123b09c9337ec.png" width="2152" height="1360" class="img_ev3q"></p>
<p>파드가 <code>Succeeded</code>되면 파드의 로그를 확인할 수도 있습니다. 사전 컴파일 작업은 <code>~15분</code> 동안 실행됩니다. 완료되면 출력에 다음이 표시됩니다:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">2023-07-29 09:42:42.000310: INFO ||PARALLEL_COMPILE||: Starting parallel compilations of the extracted graphs2023-07-29 09:42:42.000312: INFO ||PARALLEL_COMPILE||: Compiling /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.406_16969875447143373016.hlo.pb using following command: neuronx-cc compile —target=trn1 —framework XLA /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.406_16969875447143373016.hlo.pb —model-type=transformer —verbose=35 —output /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.406_16969875447143373016.neff</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023-07-29 09:42:42.000313: INFO ||PARALLEL_COMPILE||: Compiling /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.22250_9219523464496887986.hlo.pb using following command: neuronx-cc compile —target=trn1 —framework XLA /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.22250_9219523464496887986.hlo.pb —model-type=transformer —verbose=35 —output /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.22250_9219523464496887986.neff</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023-07-29 09:42:42.000314: INFO ||PARALLEL_COMPILE||: Compiling /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.25434_3000743782456078279.hlo.pb using following command: neuronx-cc compile —target=trn1 —framework XLA /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.25434_3000743782456078279.hlo.pb —model-type=transformer —verbose=35 —output /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.25434_3000743782456078279.neff</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023-07-29 09:42:42.000315: INFO ||PARALLEL_COMPILE||: Compiling /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.25637_13822314547392343350.hlo.pb using following command: neuronx-cc compile —target=trn1 —framework XLA /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.25637_13822314547392343350.hlo.pb —model-type=transformer —verbose=35 —output /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.25637_13822314547392343350.neff</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023-07-29 09:42:42.000316: INFO ||PARALLEL_COMPILE||: Compiling /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.21907_15179678551789598088.hlo.pb using following command: neuronx-cc compile —target=trn1 —framework XLA /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.21907_15179678551789598088.hlo.pb —model-type=transformer —verbose=35 —output /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.21907_15179678551789598088.neff</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">.....</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Compiler status PASS</span><br></span></code></pre></div></div>
<p>새로운 사전 훈련 캐시 파일이 FSx for Lustre에 저장됩니다.</p>
<p><img decoding="async" loading="lazy" alt="Alt text" src="/ai-on-eks/ko/assets/images/cache-c20ffd2f2f08427c018edbd418f745af.png" width="1448" height="286" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="4단계-두-개의-trn132xlarge-인스턴스로-64개의-neuron-코어를-사용하여-bert-사전-훈련-작업-시작">4단계: 두 개의 trn1.32xlarge 인스턴스로 64개의 Neuron 코어를 사용하여 BERT 사전 훈련 작업 시작<a href="#4단계-두-개의-trn132xlarge-인스턴스로-64개의-neuron-코어를-사용하여-bert-사전-훈련-작업-시작" class="hash-link" aria-label="4단계: 두 개의 trn1.32xlarge 인스턴스로 64개의 Neuron 코어를 사용하여 BERT 사전 훈련 작업 시작에 대한 직접 링크" title="4단계: 두 개의 trn1.32xlarge 인스턴스로 64개의 Neuron 코어를 사용하여 BERT 사전 훈련 작업 시작에 대한 직접 링크" translate="no">​</a></h4>
<p>이제 WikiCorpus 데이터로 BERT-large 모델을 훈련하는 최종 단계에 있습니다.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token builtin class-name">cd</span><span class="token plain"> infra/trainium-inferentia/examples/dp-bert-large-pretrain</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token function" style="color:#d73a49">chmod</span><span class="token plain"> +x </span><span class="token number" style="color:#36acaa">3</span><span class="token plain">-bert-pretrain.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./3-bert-pretrain.sh</span><br></span></code></pre></div></div>
<p>다음 명령으로 작업을 모니터링합니다. 이 작업은 30GB 이상의 데이터를 훈련하므로 몇 시간이 걸릴 수 있습니다.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get vcjob</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get pods </span><span class="token comment" style="color:#999988;font-style:italic"># 두 개의 파드가 default 네임스페이스에서 실행됩니다</span><br></span></code></pre></div></div>
<p>Neuron 사용량을 모니터링하려면 EC2 콘솔에서 SSM(Systems Manager)을 사용하여 Trainium EC2 인스턴스 중 하나에 로그인할 수 있습니다. 로그인한 후 neuron-ls 명령을 실행하면 다음과 유사한 출력을 받게 됩니다.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">root@ip-100-64-229-201 aws-efa-installer</span><span class="token punctuation" style="color:#393A34">]</span><span class="token comment" style="color:#999988;font-style:italic"># neuron-ls</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">instance-type: trn1.32xlarge</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">instance-id: i-04b476a6a0e686980</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+--------+--------+--------+---------------+---------+--------+------------------------------------------+---------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> NEURON </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> NEURON </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> NEURON </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> CONNECTED </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> PCI </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> PID </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> COMMAND </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> RUNTIME </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> DEVICE </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> CORES </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> MEMORY </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> DEVICES </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> BDF </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> VERSION </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+--------+--------+--------+---------------+---------+--------+------------------------------------------+---------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">32</span><span class="token plain"> GB </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">12</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">3</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">4</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">1</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">10</span><span class="token plain">:1c.0 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">109459</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> python3 </span><span class="token parameter variable" style="color:#36acaa">-m</span><span class="token plain"> torch_neuronx.distributed</span><span class="token punctuation" style="color:#393A34">..</span><span class="token punctuation" style="color:#393A34">..</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2.15</span><span class="token plain">.11 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">32</span><span class="token plain"> GB </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">13</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">0</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">5</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">10</span><span class="token plain">:1d.0 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">109459</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> python3 </span><span class="token parameter variable" style="color:#36acaa">-m</span><span class="token plain"> torch_neuronx.distributed</span><span class="token punctuation" style="color:#393A34">..</span><span class="token punctuation" style="color:#393A34">..</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2.15</span><span class="token plain">.11 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">32</span><span class="token plain"> GB </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">14</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">1</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">6</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">3</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> a0:1c.0 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">109459</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> python3 </span><span class="token parameter variable" style="color:#36acaa">-m</span><span class="token plain"> torch_neuronx.distributed</span><span class="token punctuation" style="color:#393A34">..</span><span class="token punctuation" style="color:#393A34">..</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2.15</span><span class="token plain">.11 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">3</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">32</span><span class="token plain"> GB </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">15</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">2</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">7</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">0</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> a0:1d.0 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">109459</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> python3 </span><span class="token parameter variable" style="color:#36acaa">-m</span><span class="token plain"> torch_neuronx.distributed</span><span class="token punctuation" style="color:#393A34">..</span><span class="token punctuation" style="color:#393A34">..</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2.15</span><span class="token plain">.11 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">4</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">32</span><span class="token plain"> GB </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">7</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">8</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">5</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">20</span><span class="token plain">:1b.0 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">109459</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> python3 </span><span class="token parameter variable" style="color:#36acaa">-m</span><span class="token plain"> torch_neuronx.distributed</span><span class="token punctuation" style="color:#393A34">..</span><span class="token punctuation" style="color:#393A34">..</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2.15</span><span class="token plain">.11 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">5</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">32</span><span class="token plain"> GB </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">4</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">9</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">6</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">20</span><span class="token plain">:1c.0 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">109459</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> python3 </span><span class="token parameter variable" style="color:#36acaa">-m</span><span class="token plain"> torch_neuronx.distributed</span><span class="token punctuation" style="color:#393A34">..</span><span class="token punctuation" style="color:#393A34">..</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2.15</span><span class="token plain">.11 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">6</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">32</span><span class="token plain"> GB </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">5</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">10</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">7</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">90</span><span class="token plain">:1b.0 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">109459</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> python3 </span><span class="token parameter variable" style="color:#36acaa">-m</span><span class="token plain"> torch_neuronx.distributed</span><span class="token punctuation" style="color:#393A34">..</span><span class="token punctuation" style="color:#393A34">..</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2.15</span><span class="token plain">.11 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">7</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">32</span><span class="token plain"> GB </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">3</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">6</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">11</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">4</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">90</span><span class="token plain">:1c.0 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">109459</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> python3 </span><span class="token parameter variable" style="color:#36acaa">-m</span><span class="token plain"> torch_neuronx.distributed</span><span class="token punctuation" style="color:#393A34">..</span><span class="token punctuation" style="color:#393A34">..</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2.15</span><span class="token plain">.11 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">8</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">32</span><span class="token plain"> GB </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">4</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">11</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">12</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">9</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">20</span><span class="token plain">:1d.0 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">109459</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> python3 </span><span class="token parameter variable" style="color:#36acaa">-m</span><span class="token plain"> torch_neuronx.distributed</span><span class="token punctuation" style="color:#393A34">..</span><span class="token punctuation" style="color:#393A34">..</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2.15</span><span class="token plain">.11 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">9</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">32</span><span class="token plain"> GB </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">5</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">8</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">13</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">10</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">20</span><span class="token plain">:1e.0 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">109459</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> python3 </span><span class="token parameter variable" style="color:#36acaa">-m</span><span class="token plain"> torch_neuronx.distributed</span><span class="token punctuation" style="color:#393A34">..</span><span class="token punctuation" style="color:#393A34">..</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2.15</span><span class="token plain">.11 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">10</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">32</span><span class="token plain"> GB </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">6</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">9</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">14</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">11</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">90</span><span class="token plain">:1d.0 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">109459</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> python3 </span><span class="token parameter variable" style="color:#36acaa">-m</span><span class="token plain"> torch_neuronx.distributed</span><span class="token punctuation" style="color:#393A34">..</span><span class="token punctuation" style="color:#393A34">..</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2.15</span><span class="token plain">.11 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">11</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">32</span><span class="token plain"> GB </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">7</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">10</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">15</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">8</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">90</span><span class="token plain">:1e.0 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">109459</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> python3 </span><span class="token parameter variable" style="color:#36acaa">-m</span><span class="token plain"> torch_neuronx.distributed</span><span class="token punctuation" style="color:#393A34">..</span><span class="token punctuation" style="color:#393A34">..</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2.15</span><span class="token plain">.11 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">12</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">32</span><span class="token plain"> GB </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">8</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">15</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">0</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">13</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">10</span><span class="token plain">:1e.0 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">109459</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> python3 </span><span class="token parameter variable" style="color:#36acaa">-m</span><span class="token plain"> torch_neuronx.distributed</span><span class="token punctuation" style="color:#393A34">..</span><span class="token punctuation" style="color:#393A34">..</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2.15</span><span class="token plain">.11 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">13</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">32</span><span class="token plain"> GB </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">9</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">12</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">1</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">14</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">10</span><span class="token plain">:1b.0 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">109459</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> python3 </span><span class="token parameter variable" style="color:#36acaa">-m</span><span class="token plain"> torch_neuronx.distributed</span><span class="token punctuation" style="color:#393A34">..</span><span class="token punctuation" style="color:#393A34">..</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2.15</span><span class="token plain">.11 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">14</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">32</span><span class="token plain"> GB </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">10</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">13</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">2</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">15</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> a0:1e.0 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">109459</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> python3 </span><span class="token parameter variable" style="color:#36acaa">-m</span><span class="token plain"> torch_neuronx.distributed</span><span class="token punctuation" style="color:#393A34">..</span><span class="token punctuation" style="color:#393A34">..</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2.15</span><span class="token plain">.11 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">15</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">32</span><span class="token plain"> GB </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">11</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">14</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">3</span><span class="token plain">, </span><span class="token number" style="color:#36acaa">12</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> a0:1b.0 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">109459</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> python3 </span><span class="token parameter variable" style="color:#36acaa">-m</span><span class="token plain"> torch_neuronx.distributed</span><span class="token punctuation" style="color:#393A34">..</span><span class="token punctuation" style="color:#393A34">..</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2.15</span><span class="token plain">.11 </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+--------+--------+--------+---------------+---------+--------+------------------------------------------+---------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<p>뉴런 코어의 실시간 사용량을 제공하는 <code>neuron-top</code>을 실행할 수도 있습니다. 아래는 32개의 모든 뉴런 코어의 사용량을 보여줍니다.</p>
<p><img decoding="async" loading="lazy" alt="Alt text" src="/ai-on-eks/ko/assets/images/neuron-top-15b215db91829995ded8d938dc8b3ef8.png" width="2116" height="1204" class="img_ev3q"></p>
<p>작업을 종료  하려면 다음 명령을 실행할 수 있습니다:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get vcjob </span><span class="token comment" style="color:#999988;font-style:italic"># 작업 이름 가져오기</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl delete </span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain">ENTER_JOB_NAME</span><span class="token operator" style="color:#393A34">&gt;</span><br></span></code></pre></div></div>
<div class="collapsibleContent_q3kw"><div class="header_QCEw"><h2><span>정리</span></h2><span class="icon_PckA">👈</span></div></div>
<div class="theme-admonition theme-admonition-caution admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>주의</div><div class="admonitionContent_BuS1"><p>AWS 계정에 원치 않는 요금이 청구되지 않도록 이 배포 중에 생성된 모든 AWS 리소스를 삭제하세요</p></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/awslabs/ai-on-eks/blob/main/website/docs/infra/trainium.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>페이지 편집</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="문서 페이지"><a class="pagination-nav__link pagination-nav__link--prev" href="/ai-on-eks/ko/docs/infra/jupyterhub"><div class="pagination-nav__sublabel">이전</div><div class="pagination-nav__label">EKS 기반 JupyterHub</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ai-on-eks/ko/docs/infra/troubleshooting"><div class="pagination-nav__sublabel">다음</div><div class="pagination-nav__label">문제 해결</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#솔루션-아키텍처" class="table-of-contents__link toc-highlight">솔루션 아키텍처</a></li><li><a href="#사전-요구-사항" class="table-of-contents__link toc-highlight">사전 요구 사항</a></li><li><a href="#배포" class="table-of-contents__link toc-highlight">배포</a></li><li><a href="#리소스-확인" class="table-of-contents__link toc-highlight">리소스 확인</a></li><li><a href="#aws-cloudwatch-및-neuron-monitor를-사용한-관측성" class="table-of-contents__link toc-highlight">AWS CloudWatch 및 Neuron Monitor를 사용한 관측성</a></li><li><a href="#torchx-및-eks를-사용한-trainium에서의-분산-pytorch-훈련" class="table-of-contents__link toc-highlight">TorchX 및 EKS를 사용한 Trainium에서의 분산 PyTorch 훈련</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">참여하기</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/awslabs/ai-on-eks" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Built with ❤️ at AWS  <br> © ${new Date().getFullYear()} Amazon.com, Inc. or its affiliates. All Rights Reserved</div></div></div></footer><script defer="" src="https://static.cloudflareinsights.com/beacon.min.js" data-cf-beacon="{&quot;token&quot;: &quot;7fbc7ab02fae4767b1af2588eba0cdf2&quot;}"></script></div>
</body>
</html>